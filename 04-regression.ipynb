{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRCQfI4o9f0k"
   },
   "source": [
    "Regression and Stochastic Gradient Descent\n",
    "===================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression consists in finding a model $f$ that depends on parameters $\\theta$ and that verifies $f(\\theta, x_i) = y_i$ for a given set of $(x_i, y_i)_{i=1..n}$. \n",
    "\n",
    "Regression can be recast as an optimization problem, for example by minimizing the loss: \n",
    "\n",
    "\\begin{equation}\n",
    "L = \\sum_i \\| y_i - f(\\theta, x_i) \\|_2^2\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressing between 2 squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to visualize a 2D -> 1D function as contours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_contours(f):     \n",
    "    delta = 0.1\n",
    "    xsteps = np.arange(-4.0, 4.0, delta)\n",
    "    ysteps = np.arange(-3.0, 3.0, delta)\n",
    "    Z = np.array([[f(torch.tensor([x, y])) for x in xsteps] for y in ysteps])\n",
    "    X, Y = np.meshgrid(xsteps, ysteps)\n",
    "    pyplot.contour(X, Y, Z, levels=np.arange(Z.min(), Z.max(), 0.05 * (Z.max() - Z.min())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complex function to minimize (convention: we always minimize rather than maximize)\n",
    "\n",
    "Note that the function is not necessarily differentiable everywhere..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): \n",
    "    return torch.sin(x[0] + 1.1) + torch.sin(x[1]) + 0.4  * (torch.abs(x[0] - 2.5) + torch.abs(x[1] + .5))\n",
    "\n",
    "plot_with_contours(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting point\n",
    "x = torch.tensor([0.0, 0.0])\n",
    "\n",
    "# set the learning rate\n",
    "learning_rate = 0.5\n",
    "\n",
    "objectives = []\n",
    "points = []\n",
    "for it in range(20):    \n",
    "    points.append(x.numpy())   # logging \n",
    "    \n",
    "    # we will need a gradient wrt. x\n",
    "    x.requires_grad = True\n",
    "    \n",
    "    # call the function, record dependencies for the gradient\n",
    "    y = f(x)\n",
    "        \n",
    "    print(it, y.item())\n",
    "    objectives.append(y.item()) # logging\n",
    "    \n",
    "    # compute gradients\n",
    "    y.backward()    \n",
    "    \n",
    "    # update current solution\n",
    "    x = x.data - learning_rate * x.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(objectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(points)\n",
    "plot_with_contours(f)\n",
    "pyplot.plot(points[:, 0], points[:, 1], 'ro-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: is this a global minimum? \n",
    "\n",
    "Try changing the initial value to something else to get a better objective value\n",
    "\n",
    "Try changing the learning rate to 2 and to 0.02. What happens?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "autograd_tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
